{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexSgt/kohya_ss_colab/blob/master/Colab_GUI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='success', description='✔ Done', disabled=True, layout=Layout(min_width='50px'), style=But…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e7796537c9148e486b93b1dbd426075"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown # Install/Update Kohya_ss WebUI\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "from subprocess import getoutput\n",
        "import ipywidgets as widgets\n",
        "import sys\n",
        "import fileinput\n",
        "import os\n",
        "import time\n",
        "\n",
        "#@markdown Save to GDrive\n",
        "gdrive = False #@param {type: \"boolean\"}\n",
        "\n",
        "if gdrive:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "\n",
        "if not gdrive:\n",
        "    print('\u001b[1;31mGdrive not connected, using colab storage ...')\n",
        "    time.sleep(4)\n",
        "    !mkdir -p /content/gdrive/MyDrive/\n",
        "with capture.capture_output() as cap:\n",
        "    def inf(msg, style, wdth):\n",
        "        inf = widgets.Button(description=msg, disabled=True, button_style=style, layout=widgets.Layout(min_width=wdth))\n",
        "        display(inf)\n",
        "\n",
        "    %mkdir -p /content/gdrive/MyDrive/sd\n",
        "    %cd /content/gdrive/MyDrive/sd\n",
        "    !git clone https://github.com/AlexSgt/kohya_ss_colab kohya_ss\n",
        "    !mkdir -p /content/gdrive/MyDrive/sd/kohya_ss/cache/huggingface\n",
        "    !ln -s /content/gdrive/MyDrive/sd/kohya_ss/cache/huggingface /root/.cache/\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "    %cd /content/gdrive/MyDrive/sd/kohya_ss/\n",
        "    !git reset --hard\n",
        "    time.sleep(1)\n",
        "print('\u001b[1;32m')\n",
        "!git pull\n",
        "clear_output()\n",
        "inf('\\u2714 Done','success', '50px')"
      ],
      "metadata": {
        "id": "xF0KWC99LHl0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9e7796537c9148e486b93b1dbd426075",
            "f6bfab5486c84ef79d12505b3383e202",
            "8288b80543494081a69364b64e52b9c6"
          ]
        },
        "outputId": "9777e5ff-f49b-4ba8-e6e7-de0fd14cb0ad"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='success', description='✔ Done', disabled=True, layout=Layout(min_width='50px'), style=But…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17bf6935b54b41ebbf7b91020180db57"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown # Requirements\n",
        "\n",
        "print('\u001b[1;32mInstalling requirements...')\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "    %cd /content/gdrive/MyDrive/sd/kohya_ss/\n",
        "    # !pip install torch==1.12.1+cu116 torchvision==0.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "    !pip install -r requirements.txt\n",
        "\n",
        "clear_output()\n",
        "inf('\\u2714 Done','success', '50px')"
      ],
      "metadata": {
        "id": "JwvimXEoLHl1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "17bf6935b54b41ebbf7b91020180db57",
            "5a26709bb3fb42d38fd83a80171770c4",
            "3680bd0b171149058db8d792783787cc"
          ]
        },
        "outputId": "33e2c705-7616-430e-f352-92ecf8182267"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Presetting of trigger word and steps\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "folders = ['input', 'output', 'log', 'config']\n",
        "base_path = '/content/gdrive/MyDrive/sd/kohya_ss/Lora/'\n",
        "trigger_word = \"sizovadina\" #@param {type:\"string\"}\n",
        "\n",
        "for folder in folders:\n",
        "  os.makedirs(base_path + folder, exist_ok=True)\n",
        "\n",
        "input_folder_path = base_path + folders[0] \n",
        "print(f\"Uploading instance images to {input_folder_path}\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "num_files = len([k for k in uploaded.keys() if '.txt' not in k])\n",
        "CONST = 1500\n",
        "\n",
        "#If your value is less than %step_limit%, then %step_limit% will be the default\n",
        "step_limit = 100 #@param {type:\"integer\"}\n",
        "\n",
        "if int(CONST / num_files) < step_limit:\n",
        "  num_f = step_limit\n",
        "else:\n",
        "  num_f = int(CONST / num_files)\n",
        "\n",
        "num_input = input_folder_path + f'/{num_f}_{trigger_word}'\n",
        "os.makedirs(num_input, exist_ok=True)\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    dst_path = os.path.join(num_input, filename)\n",
        "    shutil.move(filename, dst_path)"
      ],
      "metadata": {
        "id": "W9p0s5j-AjTT",
        "outputId": "76d89473-6987-44b0-8188-302b9496020d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading instance images to /content/gdrive/MyDrive/sd/kohya_ss/Lora/input\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cae184b3-54c2-4e7a-8ade-d1bc5847742d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cae184b3-54c2-4e7a-8ade-d1bc5847742d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving img0001.jpg to img0001.jpg\n",
            "Saving img0002.jpg to img0002.jpg\n",
            "Saving img0003.jpg to img0003.jpg\n",
            "Saving img0004.jpg to img0004.jpg\n",
            "Saving img0005.jpg to img0005.jpg\n",
            "Saving img0006.jpg to img0006.jpg\n",
            "Saving img0007.jpg to img0007.jpg\n",
            "Saving img0008.jpg to img0008.jpg\n",
            "Saving img0009.jpg to img0009.jpg\n",
            "Saving img0010.jpg to img0010.jpg\n",
            "Saving img0011.jpg to img0011.jpg\n",
            "Saving img0012.jpg to img0012.jpg\n",
            "Saving img0013.jpg to img0013.jpg\n",
            "Saving img0014.jpg to img0014.jpg\n",
            "Saving img0015.jpg to img0015.jpg\n",
            "Saving img0016.jpg to img0016.jpg\n",
            "Saving img0017.jpg to img0017.jpg\n",
            "Saving img0018.jpg to img0018.jpg\n",
            "Saving img0019.jpg to img0019.jpg\n",
            "Saving img0020.jpg to img0020.jpg\n",
            "Saving img0021.jpg to img0021.jpg\n",
            "Saving img0022.jpg to img0022.jpg\n",
            "Saving img0023.jpg to img0023.jpg\n",
            "Saving img0024.jpg to img0024.jpg\n",
            "Saving img0025.jpg to img0025.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Load CSS...\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://5070f79f3bc05cb945.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n",
            "Save as...\n",
            "Captioning files in Lora/input/100_sizovadina...\n",
            "python3 \"finetune/make_captions.py\" --batch_size=\"1\" --num_beams=\"1\" --top_p=\"0.9\" --max_length=\"75\" --min_length=\"5\" --beam_search --caption_extension=\".txt\" \"Lora/input/100_sizovadina\" --caption_weights=\"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth\"\n",
            "2023-04-22 14:10:05.543097: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-22 14:10:05.806095: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-04-22 14:10:06.947903: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-04-22 14:10:06.948109: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-04-22 14:10:06.948137: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Current Working Directory is:  /content/gdrive/MyDrive/sd/kohya_ss\n",
            "load images from /content/gdrive/MyDrive/sd/kohya_ss/Lora/input/100_sizovadina\n",
            "found 25 images.\n",
            "loading BLIP caption: https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth\n",
            "Downloading (…)solve/main/vocab.txt: 100% 232k/232k [00:00<00:00, 6.92MB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 28.0/28.0 [00:00<00:00, 4.11kB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 570/570 [00:00<00:00, 252kB/s]\n",
            "100% 1.66G/1.66G [00:18<00:00, 99.1MB/s]\n",
            "load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth\n",
            "BLIP loaded\n",
            "100% 25/25 [00:16<00:00,  1.49it/s]\n",
            "done!\n",
            "...captioning done\n",
            "Captioning files in Lora/input/100_sizovadina...\n",
            "python3 \"finetune/make_captions.py\" --batch_size=\"2\" --num_beams=\"1\" --top_p=\"0.9\" --max_length=\"75\" --min_length=\"5\" --beam_search --caption_extension=\".txt\" \"Lora/input/100_sizovadina\" --caption_weights=\"https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth\"\n",
            "2023-04-22 14:13:23.036291: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-22 14:13:23.225843: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-04-22 14:13:24.468083: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-04-22 14:13:24.468224: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-04-22 14:13:24.468245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Current Working Directory is:  /content/gdrive/MyDrive/sd/kohya_ss\n",
            "load images from /content/gdrive/MyDrive/sd/kohya_ss/Lora/input/100_sizovadina\n",
            "found 25 images.\n",
            "loading BLIP caption: https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth\n",
            "load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth\n",
            "BLIP loaded\n",
            "100% 25/25 [00:08<00:00,  2.99it/s]\n",
            "done!\n",
            "...captioning done\n"
          ]
        }
      ],
      "source": [
        "#@markdown # Start Kohya ss WebUI\n",
        "\n",
        "User = \"\" #@param {type:\"string\"}\n",
        "Password = \"\" #@param {type:\"string\"}\n",
        "#@markdown - Add credentials to your Gradio interface (optional).\n",
        "\n",
        "if User and Password:\n",
        "    !python /content/gdrive/MyDrive/sd/kohya_ss/kohya_gui.py --username $User --password $Password\n",
        "else:\n",
        "    !python /content/gdrive/MyDrive/sd/kohya_ss/kohya_gui.py"
      ],
      "metadata": {
        "id": "2BCEP_xXLHl2",
        "outputId": "6195ef12-8972-4d14-ac1e-c415909dc32e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9e7796537c9148e486b93b1dbd426075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "✔ Done",
            "disabled": true,
            "icon": "",
            "layout": "IPY_MODEL_f6bfab5486c84ef79d12505b3383e202",
            "style": "IPY_MODEL_8288b80543494081a69364b64e52b9c6",
            "tooltip": ""
          }
        },
        "f6bfab5486c84ef79d12505b3383e202": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": "50px",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8288b80543494081a69364b64e52b9c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "17bf6935b54b41ebbf7b91020180db57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "✔ Done",
            "disabled": true,
            "icon": "",
            "layout": "IPY_MODEL_5a26709bb3fb42d38fd83a80171770c4",
            "style": "IPY_MODEL_3680bd0b171149058db8d792783787cc",
            "tooltip": ""
          }
        },
        "5a26709bb3fb42d38fd83a80171770c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": "50px",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3680bd0b171149058db8d792783787cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}